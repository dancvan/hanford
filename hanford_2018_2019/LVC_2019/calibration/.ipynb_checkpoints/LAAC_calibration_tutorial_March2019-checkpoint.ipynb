{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2019  Madeline Wade\n",
    "#\n",
    "# This program is free software; you can redistribute it and/or modify it\n",
    "# under the terms of the GNU General Public License as published by the\n",
    "# Free Software Foundation; either version 2 of the License, or (at your\n",
    "# option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful, but\n",
    "# WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General\n",
    "# Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License along\n",
    "# with this program; if not, write to the Free Software Foundation, Inc.,\n",
    "# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: HOW TO USE THIS SCRIPT\n",
    "# This jupyter notebook is meant to be run on your local machine.\n",
    "# Running the jupyter notebook locally will require some packages to be installed.  Installation and set-up\n",
    "# instructions can be found at https://dcc.ligo.org/LIGO-G1900392.\n",
    "# Everywhere you see a TODO below is a spot where you should answer some questions or add some code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gwpy.plot import BodePlot\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from gwpy.frequencyseries import FrequencySeries\n",
    "from gwpy.signal.filter_design import fir_from_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the file containing all of the calibration models.  These are models for the inverse of the sensing function,\n",
    "# the total acutation function, each stage of the acutation function separately, and the overall response function. \n",
    "# As a reminder, the response function is\n",
    "#     R = (1+G)/C, where G = C*D*A\n",
    "# G is the open loop gain, C is the sensing function, A is the actuation function, and D are the digital DARM filters.\n",
    "# TODO: You'll need to modify this line to point to the location of L1DCS_test.npz if it's not in your working directory.\n",
    "models = np.load(\"L1DCS_test.npz\")\n",
    "# The models were all calculated at specific frequencies.  Below we pull out this frequency array for plotting later on. \n",
    "freqs = models[\"response_function\"][0]\n",
    "f0 = freqs[0]\n",
    "df = freqs[1]-freqs[0]\n",
    "fNyq = freqs[-1]\n",
    "# The response function was stored as separate real and imaginary parts in the file, so we're just \n",
    "# putting it all together as a gwpy FrequencySeries object below.  \n",
    "# (Sidenote: If you're new to Python, there will be a bit of Python jargon throughout. Apologies! You can just ignore\n",
    "# most of this jargon.  You should be able to follow along anyway.)\n",
    "response_function = FrequencySeries(models[\"response_function\"][1] + 1j*models[\"response_function\"][2], f0 = f0, df = df)\n",
    "# Same as above, but now for the overall acutation function (A)\n",
    "actuation_function = FrequencySeries(models[\"act_model\"][1] + 1j*models[\"act_model\"][2], f0 = f0, df = df)\n",
    "# Same as above, but now for the inverse sensing function (1/C)\n",
    "inv_sensing_function = FrequencySeries(models[\"invsens_model\"][1] + 1j*models[\"invsens_model\"][2], f0 = f0, df = df)\n",
    "\n",
    "# It will also be useful to look at each stage of the actuation separately, so below we put together FrequencySeries\n",
    "# objects for the TST, PUM, and UIM stages of the actuation.\n",
    "uim_actuation_function = FrequencySeries(models[\"uim_model\"][1] + 1j*models[\"uim_model\"][2], f0 = f0, df = df)\n",
    "pum_actuation_function = FrequencySeries(models[\"pum_model\"][1] + 1j*models[\"pum_model\"][2], f0 = f0, df = df)\n",
    "tst_actuation_function = FrequencySeries(models[\"tst_model\"][1] + 1j*models[\"tst_model\"][2], f0 = f0, df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the different components of the calibration\n",
    "# First, let's make a bode plot of the response function\n",
    "plot = BodePlot(response_function, frequencies=freqs, dB=False, color='#ee0000', linewidth=2)\n",
    "plot.add_frequencyseries(actuation_function, dB=False, color='#4ba6ff',linewidth=2)\n",
    "plot.add_frequencyseries(inv_sensing_function, dB=False, color=\"#94ded7\", linewidth=2)\n",
    "plot.legend([r\"Response function\",r\"Actuation function\",r\"Inverse sensing function\"])\n",
    "plot.maxes.set_yscale('log')\n",
    "plot.paxes.set_yscale('linear')\n",
    "plot.maxes.set_xlim(5,5000)\n",
    "plot.paxes.set_xlim(5,5000)\n",
    "plot.show()\n",
    "\n",
    "# TODO: Looking at the resulting plot, discuss the following questions:\n",
    "# 1) At which frequencies (low, mid, high) will the actuation function make its biggest contribution to h(t) reconstruction?\n",
    "# 2) At which frequencies (low, mid, high) will the inverse sensing function make its biggest contribution to h(t) reconstruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's take a look at the break down of the actuation chain\n",
    "plot = BodePlot(uim_actuation_function, frequencies=freqs, dB=False, color='#ee0000', linewidth=2)\n",
    "plot.add_frequencyseries(pum_actuation_function, dB=False, color='#4ba6ff',linewidth=2)\n",
    "plot.add_frequencyseries(tst_actuation_function, dB=False, color=\"#94ded7\", linewidth=2)\n",
    "plot.legend([r\"UIM actuation function\",r\"PUM actuation function\",r\"TST actuation function\"])\n",
    "plot.maxes.set_yscale('log')\n",
    "plot.paxes.set_yscale('linear')\n",
    "plot.maxes.set_xlim(5,5000)\n",
    "plot.paxes.set_xlim(5,5000)\n",
    "plot.maxes.set_ylim(1e-45,1)\n",
    "plot.show()\n",
    "# TODO: Looking at the resulting plot, discuss the following questions\n",
    "# 1) Discuss notable differences in the frequency evolution of each stage of the actuation. \n",
    "# 2) In theory, if you find that the actuation function contains large uncertainties around 100 Hz after performing\n",
    "#    some calibration measurements, which stage(s) of the actuation should you focus on for improving this uncertainty?\n",
    "# 3) In a new cell below, create a plot that zooms in on the Bode plot below from 5 to 30 Hz.  At what frequency does \n",
    "#    the TST stage become the most dominant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to make filters out of these functions.  Recall, a filter is an object that modifies time series data\n",
    "# in a known way to obtain a desired results.  In the frequency domain, this is a simple multiplication of the \n",
    "# frequency domain filter with frequency domain data.  In the time domain, this process is done by a convolution of\n",
    "# the filter with the time domain data.\n",
    "\n",
    "# Technical sidenote: For this exercise, we will make Finite Impulse Response (FIR) filters. \n",
    "# In the calibration, we actually use a combination of Infinite Impulse Response (IIR) filters and FIR filters.\n",
    "# For details about the different pipelines and why these filter choices were made, please check out one of our publications:\n",
    "# https://iopscience.iop.org/article/10.1088/1361-6382/aab658\n",
    "\n",
    "# Before we make a filter out of the frequency domain models of the acutation and inverse sensing functions,\n",
    "# we need to modify low frequency components to fall to zero.  This is called a highpass filter, since high frequency \n",
    "# components are not modified, or are allowed to \"pass\" through this filter.  The highpass filter is used to avoid \n",
    "# modeling the low frequency components (below 9 Hz) of the actuation and inverse sensing.  A very long filter would \n",
    "# be required if we tried to model these low frequency components, so by highpass filtering we can create shorter \n",
    "# filters with good accuracy.  This means we will NOT be producing accurate strain data below 9 Hz, which is okay.\n",
    "\n",
    "# We also need to modify the high frequency components of the inverse sensing to fall to zero. This is called a\n",
    "# lowpass filter, since low frequency components are allowed to \"pass\" through.\n",
    "# The high frequency components of the inverse sensing function need to be rolled off because the \n",
    "# inverse sensing function blows up at high frequencies, which creates an unphysics filter.\n",
    "\n",
    "# For this tutorial, we'll do construct high and low pass filters in a really simple way with just half of a \n",
    "# Hann window on the magnitudes.  \n",
    "\n",
    "# High pass filter the actuation and inverse sensing functions below 9 Hz.  \n",
    "HPcorner_freq = 9 # this is the frequency (in Hz) below which we are rolling off the model components\n",
    "samples_to_HPcorner = int(HPcorner_freq/df)\n",
    "hp_hann = np.hanning(samples_to_HPcorner)\n",
    "hp_hann = hp_hann[:int(samples_to_HPcorner / 2)]\n",
    "hp_hann = np.concatenate((np.zeros(samples_to_HPcorner - len(hp_hann)), hp_hann)) # We'll actually roll off to zero by about 5 Hz\n",
    "actuation_function[:samples_to_HPcorner] *= hp_hann**4\n",
    "inv_sensing_function[:samples_to_HPcorner] *= hp_hann**4\n",
    "\n",
    "# Low pass filter the inverse sensing function above 6000 Hz\n",
    "LPcorner_freq = 6000 # this is the frequency (in Hz) above which we are rolling off the model components\n",
    "samples_to_LPcorner = int((fNyq - LPcorner_freq) / df)\n",
    "lp_hann = np.hanning(2*samples_to_LPcorner)\n",
    "lp_hann = lp_hann[-samples_to_LPcorner:]\n",
    "inv_sensing_function[-samples_to_LPcorner:] *= lp_hann\n",
    "\n",
    "# We will use a built-in gwpy function to create FIR filters from our actuation and inverse sensing models.\n",
    "# To read more about the method we actually use in the production calibration tools, see\n",
    "# https://iopscience.iop.org/article/10.1088/1361-6382/aab658\n",
    "hoft_sr = 2*fNyq # The sample rate of the data must be twice the Nyquist of the models used to create the filters\n",
    "dur = 1/df # The total duration of the filter is dictated by the frequency spacing of the models\n",
    "ntaps = int(hoft_sr*dur) # The number of taps of the FIR filter will be the duration of the filter times the sample rate\n",
    "actuation_fir = fir_from_transfer(actuation_function, ntaps)\n",
    "inv_sensing_fir = fir_from_transfer(inv_sensing_function, ntaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's fetch the data. For this step, you'll need to have NDS2 installed or be on a cluster.\n",
    "# See instructions downloadable from https://dcc.ligo.org/LIGO-G1900392 for how to install NDS2 for this tutorial\n",
    "# From the gwpy documentation: \n",
    "# Note: Access to data using the nds2 client requires a Kerberos authentication ticket. \n",
    "# This can be generated from the command-line using kinit:\n",
    "#       $ kinit albert.einstein@LIGO.ORG\n",
    "# where albert.einstein should be replaced with your own LIGO.ORG identity. \n",
    "# If you donâ€™t have an active kerberos credential at the time you run TimeSeries.get, GWpy will prompt you to create one.\n",
    "  \n",
    "# This step will take a few minutes.    \n",
    "darm_err = TimeSeries.get('L1:CAL-DARM_ERR_DBL_DQ',1235184405,1235184905)\n",
    "darm_ctrl = TimeSeries.get('L1:CAL-DARM_CTRL_DBL_DQ',1235184405,1235184905)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add in code below that will filter the DARM_ERR and DARM_CTRL data with the appropriate FIR filters that you\n",
    "# created above.  You can use the built-in convolve function for a gwpy TimeSeries object, i.e.\n",
    "#          filtered_data = darm_err.convolve(FIR_filter_name)\n",
    "# Note: If you are unfamiliar with Python classes or methods, that's okay.  The takeaway is that you can filter time\n",
    "# series data using the syntax above.  In this example, darm_err is the time series data being filtered, filtered_data \n",
    "# is the output of the filtering process and FIR_filter_name is the FIR filter to filter with.\n",
    "\n",
    "# As a reminder, \\Delta L_free is contructed by\n",
    "#  \\Delta L_free = (1/C)*darm_err + A*darm_ctrl\n",
    "# and h(t) = \\Delta L_free / L\n",
    "\n",
    "# res_chain should be the output of filtering the darm_error (or residual) data\n",
    "res_chain = \n",
    "# ctrl_chain should be the output of filtering the darm_ctrl (or control) data\n",
    "ctrl_chain = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add in code below that will construct h(t) from your filtered results in the previous cell\n",
    "L = 3995.1\n",
    "hoft = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check it out! \n",
    "plot = hoft.plot()\n",
    "ax = plot.gca()\n",
    "ax.set_ylabel('Gravitational-wave amplitude [strain]')\n",
    "ax.set_title('LIGO-Livingston strain data')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check out the ASD (Amplitude Spectral Density) of the data you just made\n",
    "asd = hoft.asd(4, 2, method = \"lal_median_mean\")\n",
    "plot = asd.plot()\n",
    "ax = plot.gca()\n",
    "ax.set_xlim(10, 5000)\n",
    "ax.set_ylim(1e-24,1e-18)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the actual h(t) data from the production calibration pipeline looked like at this time\n",
    "# This step will take a few minutes.    \n",
    "hoft_C00 = TimeSeries.get('L1:GDS-CALIB_STRAIN',1235184405,1235184905)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the ASDs compare\n",
    "asd = hoft.asd(4, 2, method = \"lal_median_mean\")\n",
    "asd_C00 = hoft_C00.asd(4, 2, method = \"lal_median_mean\")\n",
    "plot = asd.plot()\n",
    "ax = plot.gca()\n",
    "ax.plot(asd_C00)\n",
    "ax.set_xlim(10, 5000)\n",
    "ax.set_ylim(1e-24,1e-18)\n",
    "plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
